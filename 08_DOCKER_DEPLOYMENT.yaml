# =============================================
# DOCKER –ò DEPLOYMENT
# =============================================

# ============================================
# –§–ê–ô–õ: backend/Dockerfile
# ============================================

FROM python:3.11-slim

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
RUN apt-get update && apt-get install -y \
    gcc \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
WORKDIR /app

# –ö–æ–ø–∏—Ä—É–µ–º requirements –ø–µ—Ä–≤—ã–º –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# –ö–æ–ø–∏—Ä—É–µ–º –∫–æ–¥
COPY . .

# –ü–æ—Ä—Ç
EXPOSE 8000

# –ö–æ–º–∞–Ω–¥–∞ –∑–∞–ø—É—Å–∫–∞
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]


# ============================================
# –§–ê–ô–õ: backend/Dockerfile.worker
# ============================================

FROM python:3.11-slim

RUN apt-get update && apt-get install -y \
    gcc \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

# Celery worker
CMD ["celery", "-A", "workers.celery_app", "worker", "--loglevel=info", "--concurrency=4"]


# ============================================
# –§–ê–ô–õ: backend/Dockerfile.beat
# ============================================

FROM python:3.11-slim

RUN apt-get update && apt-get install -y \
    gcc \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

# Celery beat (–ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫)
CMD ["celery", "-A", "workers.celery_app", "beat", "--loglevel=info"]


# ============================================
# –§–ê–ô–õ: frontend/Dockerfile
# ============================================

# Build stage
FROM node:20-alpine as build

WORKDIR /app

COPY package*.json ./
RUN npm ci

COPY . .
RUN npm run build

# Production stage
FROM nginx:alpine

COPY --from=build /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/conf.d/default.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]


# ============================================
# –§–ê–ô–õ: frontend/nginx.conf
# ============================================

server {
    listen 80;
    server_name localhost;
    root /usr/share/nginx/html;
    index index.html;

    # Gzip
    gzip on;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml;

    # SPA routing
    location / {
        try_files $uri $uri/ /index.html;
    }

    # API proxy
    location /api {
        proxy_pass http://backend:8000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    # Health check
    location /health {
        return 200 'OK';
        add_header Content-Type text/plain;
    }
}


# ============================================
# –§–ê–ô–õ: telegram-bot/Dockerfile
# ============================================

FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "bot.py"]


# ============================================
# –§–ê–ô–õ: docker-compose.yml
# ============================================

version: '3.8'

services:
  # ===================
  # –ë–ê–ó–ê –î–ê–ù–ù–´–•
  # ===================
  postgres:
    image: postgres:15-alpine
    container_name: content_postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-content_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-content_pass}
      POSTGRES_DB: ${POSTGRES_DB:-content_automation}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/migrations/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-content_user}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ===================
  # REDIS
  # ===================
  redis:
    image: redis:7-alpine
    container_name: content_redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ===================
  # BACKEND API
  # ===================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: content_backend
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-content_user}:${POSTGRES_PASSWORD:-content_pass}@postgres:5432/${POSTGRES_DB:-content_automation}
      - REDIS_URL=redis://redis:6379/0
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app
      - media_data:/app/media
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===================
  # CELERY WORKER
  # ===================
  celery_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile.worker
    container_name: content_celery_worker
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-content_user}:${POSTGRES_PASSWORD:-content_pass}@postgres:5432/${POSTGRES_DB:-content_automation}
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - backend
      - redis
    volumes:
      - ./backend:/app
      - media_data:/app/media

  # ===================
  # CELERY BEAT (SCHEDULER)
  # ===================
  celery_beat:
    build:
      context: ./backend
      dockerfile: Dockerfile.beat
    container_name: content_celery_beat
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-content_user}:${POSTGRES_PASSWORD:-content_pass}@postgres:5432/${POSTGRES_DB:-content_automation}
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - backend
      - redis
    volumes:
      - ./backend:/app

  # ===================
  # FRONTEND
  # ===================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: content_frontend
    restart: unless-stopped
    ports:
      - "3000:80"
    depends_on:
      - backend
    environment:
      - VITE_API_URL=http://localhost:8000/api/v1

  # ===================
  # TELEGRAM BOT
  # ===================
  telegram_bot:
    build:
      context: ./telegram-bot
      dockerfile: Dockerfile
    container_name: content_telegram_bot
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - API_URL=http://backend:8000/api/v1
    depends_on:
      - backend

  # ===================
  # FLOWER (Celery –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥)
  # ===================
  flower:
    image: mher/flower:0.9.7
    container_name: content_flower
    restart: unless-stopped
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - FLOWER_PORT=5555
    ports:
      - "5555:5555"
    depends_on:
      - redis
      - celery_worker

volumes:
  postgres_data:
  redis_data:
  media_data:


# ============================================
# –§–ê–ô–õ: docker-compose.prod.yml
# ============================================

version: '3.8'

# Production overrides
services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    restart: always
    environment:
      - DEBUG=false
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  celery_worker:
    restart: always
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  frontend:
    restart: always

  postgres:
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G

  redis:
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M


# ============================================
# –§–ê–ô–õ: .env.example
# ============================================

# ===================
# APP
# ===================
APP_NAME=Content Automation System
APP_VERSION=1.0.0
DEBUG=true

# ===================
# DATABASE
# ===================
POSTGRES_USER=content_user
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=content_automation
DATABASE_URL=postgresql://content_user:your_secure_password_here@localhost:5432/content_automation

# ===================
# REDIS
# ===================
REDIS_URL=redis://localhost:6379/0

# ===================
# JWT
# ===================
JWT_SECRET_KEY=your-super-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# ===================
# AI APIS
# ===================
ANTHROPIC_API_KEY=sk-ant-xxxx
OPENAI_API_KEY=sk-xxxx
ELEVENLABS_API_KEY=xxxx

# ===================
# VIDEO GENERATION
# ===================
HEYGEN_API_KEY=xxxx
STABILITY_API_KEY=sk-xxxx

# ===================
# SOCIAL MEDIA
# ===================
# TikTok
TIKTOK_CLIENT_KEY=xxxx
TIKTOK_CLIENT_SECRET=xxxx

# Twitter/X
TWITTER_API_KEY=xxxx
TWITTER_API_SECRET=xxxx
TWITTER_BEARER_TOKEN=xxxx

# LinkedIn
LINKEDIN_CLIENT_ID=xxxx
LINKEDIN_CLIENT_SECRET=xxxx

# YouTube
YOUTUBE_API_KEY=xxxx

# Telegram
TELEGRAM_BOT_TOKEN=xxxx

# ===================
# PAYMENTS
# ===================
STRIPE_SECRET_KEY=sk_test_xxxx
STRIPE_WEBHOOK_SECRET=whsec_xxxx

# ===================
# STORAGE (S3/R2)
# ===================
S3_ENDPOINT=https://xxxx.r2.cloudflarestorage.com
S3_ACCESS_KEY=xxxx
S3_SECRET_KEY=xxxx
S3_BUCKET=content-automation
S3_PUBLIC_URL=https://cdn.yourdomain.com

# ===================
# CORS
# ===================
CORS_ORIGINS=http://localhost:3000,https://yourdomain.com


# ============================================
# –§–ê–ô–õ: scripts/setup.sh
# ============================================

#!/bin/bash

# –°–∫—Ä–∏–ø—Ç –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

set -e

echo "üöÄ Content Automation System - Setup"
echo "======================================"

# –ü—Ä–æ–≤–µ—Ä—è–µ–º Docker
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Docker –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω."
    exit 1
fi

echo "‚úÖ Docker –Ω–∞–π–¥–µ–Ω"

# –°–æ–∑–¥–∞—ë–º .env –µ—Å–ª–∏ –Ω–µ—Ç
if [ ! -f .env ]; then
    echo "üìù –°–æ–∑–¥–∞—ë–º .env —Ñ–∞–π–ª..."
    cp .env.example .env
    echo "‚ö†Ô∏è  –ù–µ –∑–∞–±—É–¥—å—Ç–µ –∑–∞–ø–æ–ª–Ω–∏—Ç—å .env —Å–≤–æ–∏–º–∏ API –∫–ª—é—á–∞–º–∏!"
fi

# –°–æ–∑–¥–∞—ë–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
echo "üìÅ –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏..."
mkdir -p backend/media
mkdir -p backend/logs
mkdir -p frontend/dist

# –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
echo "üê≥ –ó–∞–ø—É—Å–∫–∞–µ–º Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã..."
docker-compose up -d postgres redis

# –ñ–¥—ë–º –ø–æ–∫–∞ –ë–î –ø–æ–¥–Ω–∏–º–µ—Ç—Å—è
echo "‚è≥ –ñ–¥—ë–º –∑–∞–ø—É—Å–∫–∞ PostgreSQL..."
sleep 10

# –ó–∞–ø—É—Å–∫–∞–µ–º –º–∏–≥—Ä–∞—Ü–∏–∏
echo "üìä –ó–∞–ø—É—Å–∫–∞–µ–º –º–∏–≥—Ä–∞—Ü–∏–∏ –ë–î..."
docker-compose run --rm backend alembic upgrade head

# –°–æ–∑–¥–∞—ë–º –∞–¥–º–∏–Ω–∞
echo "üë§ –°–æ–∑–¥–∞—ë–º –∞–¥–º–∏–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è..."
docker-compose run --rm backend python -c "
from app.db.session import SessionLocal
from app.models.user import User
from passlib.context import CryptContext

pwd_context = CryptContext(schemes=['bcrypt'], deprecated='auto')
db = SessionLocal()

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —É–∂–µ –∞–¥–º–∏–Ω
admin = db.query(User).filter(User.email == 'admin@example.com').first()
if not admin:
    admin = User(
        email='admin@example.com',
        password_hash=pwd_context.hash('admin123'),
        name='Admin',
        role='admin'
    )
    db.add(admin)
    db.commit()
    print('‚úÖ –ê–¥–º–∏–Ω —Å–æ–∑–¥–∞–Ω: admin@example.com / admin123')
else:
    print('‚ÑπÔ∏è  –ê–¥–º–∏–Ω —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç')
db.close()
"

# –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã
echo "üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã..."
docker-compose up -d

echo ""
echo "======================================"
echo "‚úÖ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!"
echo ""
echo "üìå –î–æ—Å—Ç—É–ø—ã:"
echo "   Frontend: http://localhost:3000"
echo "   Backend API: http://localhost:8000"
echo "   API Docs: http://localhost:8000/api/docs"
echo "   Flower (Celery): http://localhost:5555"
echo ""
echo "üîê –í—Ö–æ–¥:"
echo "   Email: admin@example.com"
echo "   –ü–∞—Ä–æ–ª—å: admin123"
echo ""
echo "‚ö†Ô∏è  –ù–µ –∑–∞–±—É–¥—å—Ç–µ:"
echo "   1. –ó–∞–ø–æ–ª–Ω–∏—Ç—å .env —Ñ–∞–π–ª API –∫–ª—é—á–∞–º–∏"
echo "   2. –°–º–µ–Ω–∏—Ç—å –ø–∞—Ä–æ–ª—å –∞–¥–º–∏–Ω–∞"
echo "======================================"


# ============================================
# –§–ê–ô–õ: scripts/deploy.sh
# ============================================

#!/bin/bash

# –°–∫—Ä–∏–ø—Ç –¥–µ–ø–ª–æ—è

set -e

echo "üöÄ Deploying Content Automation System..."

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
source .env

# Pull –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
echo "üì• Pulling latest changes..."
git pull origin main

# –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤—ã–µ –æ–±—Ä–∞–∑—ã
echo "üî® Building Docker images..."
docker-compose -f docker-compose.yml -f docker-compose.prod.yml build

# –ó–∞–ø—É—Å–∫–∞–µ–º –º–∏–≥—Ä–∞—Ü–∏–∏
echo "üìä Running migrations..."
docker-compose run --rm backend alembic upgrade head

# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–∏—Å—ã —Å zero-downtime
echo "üîÑ Restarting services..."
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d --no-deps backend
sleep 5
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d --no-deps celery_worker
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d --no-deps celery_beat
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d --no-deps frontend
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d --no-deps telegram_bot

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–¥–æ—Ä–æ–≤—å–µ
echo "üè• Health check..."
sleep 10
curl -f http://localhost:8000/health || exit 1

# –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –æ–±—Ä–∞–∑–æ–≤
echo "üßπ Cleaning up old images..."
docker image prune -f

echo "‚úÖ Deployment complete!"


# ============================================
# –§–ê–ô–õ: scripts/backup.sh
# ============================================

#!/bin/bash

# –°–∫—Ä–∏–ø—Ç –±–µ–∫–∞–ø–∞

set -e

BACKUP_DIR="./backups"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/backup_$DATE.sql.gz"

# –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ—Ç
mkdir -p $BACKUP_DIR

echo "üì¶ Creating backup..."

# –ë–µ–∫–∞–ø PostgreSQL
docker-compose exec -T postgres pg_dump -U content_user content_automation | gzip > $BACKUP_FILE

echo "‚úÖ Backup created: $BACKUP_FILE"

# –£–¥–∞–ª—è–µ–º –±–µ–∫–∞–ø—ã —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π
find $BACKUP_DIR -name "backup_*.sql.gz" -mtime +30 -delete
echo "üßπ Old backups cleaned"

# –†–∞–∑–º–µ—Ä –±–µ–∫–∞–ø–∞
ls -lh $BACKUP_FILE


# ============================================
# –§–ê–ô–õ: scripts/restore.sh
# ============================================

#!/bin/bash

# –°–∫—Ä–∏–ø—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑ –±–µ–∫–∞–ø–∞

set -e

if [ -z "$1" ]; then
    echo "Usage: ./restore.sh <backup_file.sql.gz>"
    exit 1
fi

BACKUP_FILE=$1

if [ ! -f "$BACKUP_FILE" ]; then
    echo "‚ùå File not found: $BACKUP_FILE"
    exit 1
fi

echo "‚ö†Ô∏è  This will OVERWRITE the current database!"
read -p "Are you sure? (yes/no): " confirm

if [ "$confirm" != "yes" ]; then
    echo "Cancelled"
    exit 0
fi

echo "üì¶ Restoring from $BACKUP_FILE..."

# –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–µ—Ä–≤–∏—Å—ã –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –ë–î
docker-compose stop backend celery_worker celery_beat

# –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
gunzip -c $BACKUP_FILE | docker-compose exec -T postgres psql -U content_user -d content_automation

# –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–∏—Å—ã
docker-compose start backend celery_worker celery_beat

echo "‚úÖ Restore complete!"


# ============================================
# –§–ê–ô–õ: Makefile
# ============================================

.PHONY: help setup dev prod stop logs clean test

help:
	@echo "Content Automation System - Commands"
	@echo ""
	@echo "  make setup    - First time setup"
	@echo "  make dev      - Start development environment"
	@echo "  make prod     - Start production environment"
	@echo "  make stop     - Stop all containers"
	@echo "  make logs     - View logs"
	@echo "  make clean    - Remove all containers and volumes"
	@echo "  make test     - Run tests"
	@echo "  make backup   - Create database backup"
	@echo "  make migrate  - Run database migrations"

setup:
	chmod +x scripts/*.sh
	./scripts/setup.sh

dev:
	docker-compose up -d
	@echo "üöÄ Development environment started"
	@echo "Frontend: http://localhost:3000"
	@echo "Backend: http://localhost:8000"

prod:
	docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
	@echo "üöÄ Production environment started"

stop:
	docker-compose down
	@echo "‚èπÔ∏è  All containers stopped"

logs:
	docker-compose logs -f

logs-backend:
	docker-compose logs -f backend

logs-worker:
	docker-compose logs -f celery_worker

clean:
	docker-compose down -v --rmi all
	@echo "üßπ Cleaned up"

test:
	docker-compose run --rm backend pytest

backup:
	./scripts/backup.sh

migrate:
	docker-compose run --rm backend alembic upgrade head

shell:
	docker-compose exec backend python

psql:
	docker-compose exec postgres psql -U content_user -d content_automation

redis-cli:
	docker-compose exec redis redis-cli


# ============================================
# –§–ê–ô–õ: .github/workflows/deploy.yml
# ============================================

name: Deploy

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Deploy to server
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.SERVER_HOST }}
          username: ${{ secrets.SERVER_USER }}
          key: ${{ secrets.SERVER_SSH_KEY }}
          script: |
            cd /opt/content-automation
            git pull origin main
            ./scripts/deploy.sh


# ============================================
# –§–ê–ô–õ: .github/workflows/test.yml
# ============================================

name: Tests

on:
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_pass
          POSTGRES_DB: test_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:7
        ports:
          - 6379:6379
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio
      
      - name: Run tests
        env:
          DATABASE_URL: postgresql://test_user:test_pass@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
        run: |
          cd backend
          pytest -v
